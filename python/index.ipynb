{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828393cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polars'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'polars'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Leitura do arquivo SQL\n",
    "with open('grupodemanda_202512021151.sql', 'r', encoding='utf-8') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "# Parser linha por linha com tratamento especial para strings\n",
    "def parse_line_by_line(sql_content):\n",
    "    \"\"\"Parse linha por linha com tratamento especial para strings\"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    lines = sql_content.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line.startswith('(') and '\\t (' not in line and '\t (' not in line:\n",
    "            if '(' not in line or not any(c.isdigit() for c in line[:20]):\n",
    "                continue\n",
    "        \n",
    "        # Extrair tupla da linha\n",
    "        if '(' in line and ')' in line:\n",
    "            start = line.find('(')\n",
    "            end = line.rfind(')')\n",
    "            \n",
    "            if start >= 0 and end > start:\n",
    "                tuple_content = line[start+1:end]\n",
    "                \n",
    "                # Parse manual respeitando strings\n",
    "                values = []\n",
    "                current = ''\n",
    "                in_string = False\n",
    "                \n",
    "                for char in tuple_content:\n",
    "                    if char == \"'\" and not in_string:\n",
    "                        in_string = True\n",
    "                        current += char\n",
    "                    elif char == \"'\" and in_string:\n",
    "                        in_string = False\n",
    "                        current += char\n",
    "                    elif char == ',' and not in_string:\n",
    "                        values.append(current.strip())\n",
    "                        current = ''\n",
    "                    else:\n",
    "                        current += char\n",
    "                \n",
    "                if current:\n",
    "                    values.append(current.strip())\n",
    "                \n",
    "                if len(values) >= 9 and values[0].isdigit():\n",
    "                    data_rows.append(values)\n",
    "    \n",
    "    return data_rows\n",
    "\n",
    "# Usar o parser linha por linha\n",
    "data_lines = parse_line_by_line(sql_content)\n",
    "\n",
    "print(f\"Total de linhas extraÃ­das: {len(data_lines)}\")\n",
    "\n",
    "# IDs que estavam faltando para verificar\n",
    "missing_ids = [103171, 107729, 256460, 107761, 102749, 107545, 107611, 104241, \n",
    "               96208, 434600, 107728, 95463, 107738, 96209, 256427, 107734, 107779]\n",
    "\n",
    "found_ids = [int(line[0]) for line in data_lines if line[0].isdigit()]\n",
    "print(f\"IDs encontrados: {len(found_ids)}\")\n",
    "\n",
    "missing_found = [id for id in missing_ids if id in found_ids]\n",
    "still_missing = [id for id in missing_ids if id not in found_ids]\n",
    "print(f\"IDs antes faltantes agora encontrados: {missing_found}\")\n",
    "print(f\"IDs ainda faltando: {still_missing}\")\n",
    "\n",
    "# Processar cada linha de dados\n",
    "processed_data = []\n",
    "for line in data_lines:\n",
    "    try:\n",
    "        id_val = int(line[0])\n",
    "        ativo = line[1].lower() == 'true'\n",
    "        data_criacao = line[2].strip(\"'\")\n",
    "        descricao = line[3].strip(\"'\")\n",
    "        nome = line[4].strip(\"'\")\n",
    "        # Usar 0 quando fundo_municipal_id for NULL (nÃ£o permite null na tabela)\n",
    "        fundo_municipal_id = 0 if line[7] == 'NULL' or line[7] is None or line[7] == '' else int(line[7])\n",
    "        \n",
    "        processed_data.append({\n",
    "            'id': id_val,\n",
    "            'nome': nome,\n",
    "            'descricao': descricao,\n",
    "            'fundo_municipal_id': fundo_municipal_id,\n",
    "            'ativo': ativo,\n",
    "            'data_criacao': data_criacao,\n",
    "        })\n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"Erro ao processar linha: {line[:3]}... - {e}\")\n",
    "        continue\n",
    "\n",
    "# Criar DataFrame com Polars\n",
    "df = pl.DataFrame(processed_data)\n",
    "\n",
    "# Converter data_criacao para datetime\n",
    "def parse_datetime(date_str):\n",
    "    \"\"\"Converte string de data para datetime, suportando com e sem milissegundos\"\"\"\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    except ValueError:\n",
    "        return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col('data_criacao').map_elements(parse_datetime, return_dtype=pl.Datetime('us')).alias('data_criacao')\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal de registros a importar: {len(df)}\")\n",
    "print(\"\\nPrimeiros 5 registros:\")\n",
    "print(df.head(5))\n",
    "\n",
    "# Conectar ao PostgreSQL e fazer o insert\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='agefis',\n",
    "        user='postgres',\n",
    "        password='postgres',\n",
    "        port=5432\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Query sem a coluna afinidades\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO \"fiscalizacao\".\"grupos_ocorrencia\" \n",
    "        (id, nome, descricao, fundo_municipal_id, ativo, data_criacao)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            nome = EXCLUDED.nome,\n",
    "            descricao = EXCLUDED.descricao,\n",
    "            fundo_municipal_id = EXCLUDED.fundo_municipal_id,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Converter DataFrame para lista de tuplas\n",
    "    data_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['nome'],\n",
    "            row['descricao'],\n",
    "            row['fundo_municipal_id'],\n",
    "            row['ativo'],\n",
    "            row['data_criacao']\n",
    "        )\n",
    "        for row in df.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    # Executar insert em batch\n",
    "    execute_batch(cursor, insert_query, data_to_insert, page_size=100)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"\\nâœ… {len(data_to_insert)} registros inseridos/atualizados com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao inserir dados: {e}\")\n",
    "    if 'conn' in dir():\n",
    "        conn.rollback()\n",
    "    \n",
    "finally:\n",
    "    if 'cursor' in dir():\n",
    "        cursor.close()\n",
    "    if 'conn' in dir():\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a03cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas extraÃ­das: 885\n",
      "Colunas por linha (primeiro): 33\n",
      "Colunas por linha (min/max): 33/34\n",
      "\n",
      "ğŸ“Š USUARIOS - Total de registros: 885\n",
      "shape: (3, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id      â”† login          â”† email         â”† password_hash â”† nome          â”† data_criacao  â”† ativo â”‚\n",
      "â”‚ ---     â”† ---            â”† ---           â”† ---           â”† ---           â”† ---           â”† ---   â”‚\n",
      "â”‚ i64     â”† str            â”† str           â”† str           â”† str           â”† datetime[Î¼s]  â”† bool  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 7664882 â”† leidiany.vieir â”† leidiany.viei â”† a0b4d4ceee4e7 â”† LEIDIANY      â”† 2025-08-04    â”† true  â”‚\n",
      "â”‚         â”† a              â”† ra@sr4.fortal â”† d2fa38f07071a â”† KELLY SOUSA   â”† 09:21:06.971  â”†       â”‚\n",
      "â”‚         â”†                â”† eza.â€¦         â”† 648câ€¦         â”† VIEIRA        â”†               â”†       â”‚\n",
      "â”‚ 3563060 â”† matheus.queiro â”† matheus.queir â”† b06fcaa1e1d12 â”† MATHEUS       â”† 2021-09-01    â”† true  â”‚\n",
      "â”‚         â”† z              â”† oz@agefis.for â”† fe35424416031 â”† FERREIRA DE   â”† 08:16:00      â”†       â”‚\n",
      "â”‚         â”†                â”† taleâ€¦         â”† 254eâ€¦         â”† QUEIROZ\t      â”†               â”†       â”‚\n",
      "â”‚ 1990729 â”† ouvidoria      â”† ouvidoria@sms â”† b06fcaa1e1d12 â”† Carlos        â”† 2019-10-17    â”† true  â”‚\n",
      "â”‚         â”†                â”† .fortaleza.ce â”† fe35424416031 â”† Osvaldo Matos â”† 12:41:56.826  â”†       â”‚\n",
      "â”‚         â”†                â”† .govâ€¦         â”† 254eâ€¦         â”† Fernandesâ€¦    â”†               â”†       â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ğŸ” FISCAIS - Total de registros: 885\n",
      "shape: (3, 5)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id      â”† matricula   â”† lotacao â”† data_criacao            â”† ativo â”‚\n",
      "â”‚ ---     â”† ---         â”† ---     â”† ---                     â”† ---   â”‚\n",
      "â”‚ i64     â”† str         â”† str     â”† datetime[Î¼s]            â”† bool  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 75494   â”† 8709301     â”† 37      â”† 2019-01-07 09:59:00     â”† true  â”‚\n",
      "â”‚ 4531376 â”† 45744319387 â”† 15      â”† 2022-10-26 10:22:22.156 â”† true  â”‚\n",
      "â”‚ 48140   â”† 8721401     â”† 37      â”† 2021-06-18 16:23:00     â”† true  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â³ Inserindo em 'seguranca.usuarios'...\n",
      "âœ… 885 usuÃ¡rios inseridos!\n",
      "\n",
      "â³ Inserindo em 'fiscalizacao.fiscais'...\n",
      "âœ… 885 usuÃ¡rios inseridos!\n",
      "\n",
      "â³ Inserindo em 'fiscalizacao.fiscais'...\n",
      "âœ… 885 fiscais inseridos!\n",
      "âœ… 885 fiscais inseridos!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import hashlib\n",
    "\n",
    "# Leitura do arquivo SQL\n",
    "with open('usuario_202512021153.sql', 'r', encoding='utf-8') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "# Extrair blocos de INSERT\n",
    "insert_blocks = re.findall(r'INSERT INTO usuario \\([^)]+\\) VALUES\\s+(.*?)(?=INSERT INTO|$)', sql_content, re.DOTALL)\n",
    "\n",
    "data_lines = []\n",
    "\n",
    "for block in insert_blocks:\n",
    "    # Encontrar todas as tuplas com parÃªnteses\n",
    "    pattern = r'\\(([^)]+)\\)'\n",
    "    matches = re.findall(pattern, block)\n",
    "    \n",
    "    for match in matches:\n",
    "        parts = [p.strip() for p in match.split(',')]\n",
    "        # Verificar se Ã© um dado vÃ¡lido (primeiro valor Ã© nÃºmero) e tem pelo menos as colunas esperadas\n",
    "        if len(parts) >= 21 and parts[0].isdigit():  # Precisa de pelo menos atÃ© setor_id (Ã­ndice 20)\n",
    "            data_lines.append(parts)\n",
    "\n",
    "print(f\"Total de linhas extraÃ­das: {len(data_lines)}\")\n",
    "if data_lines:\n",
    "    print(f\"Colunas por linha (primeiro): {len(data_lines[0])}\")\n",
    "    print(f\"Colunas por linha (min/max): {min(len(line) for line in data_lines)}/{max(len(line) for line in data_lines)}\")\n",
    "\n",
    "# Processar dados para a tabela usuarios\n",
    "usuarios_data = []\n",
    "fiscais_data = []\n",
    "login_counter = {}  # Para evitar logins duplicados\n",
    "usuarios_ids = set()  # Rastrear IDs de usuÃ¡rios que serÃ£o inseridos\n",
    "\n",
    "def parse_datetime_safe(date_str):\n",
    "    \"\"\"Converte string de data para datetime, suportando vÃ¡rios formatos\"\"\"\n",
    "    if not date_str or date_str == 'NULL':\n",
    "        return None\n",
    "    \n",
    "    date_str = date_str.strip(\"'\")\n",
    "    \n",
    "    # Lista de formatos para tentar\n",
    "    formats = [\n",
    "        '%Y-%m-%d %H:%M:%S.%f',  # Com milissegundos\n",
    "        '%Y-%m-%d %H:%M:%S',      # Sem milissegundos\n",
    "        '%Y-%m-%d',                # Apenas data\n",
    "    ]\n",
    "    \n",
    "    # Trata caso especial de data invÃ¡lida com \"BC\"\n",
    "    if 'BC' in date_str:\n",
    "        return None\n",
    "    \n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_unique_login(base_login, user_id):\n",
    "    \"\"\"Garante que o login seja Ãºnico adicionando um sufixo se necessÃ¡rio\"\"\"\n",
    "    if base_login not in login_counter:\n",
    "        login_counter[base_login] = 0\n",
    "        return base_login\n",
    "    \n",
    "    login_counter[base_login] += 1\n",
    "    # Gera um login Ãºnico com sufixo\n",
    "    new_login = f\"{base_login}{login_counter[base_login]}\"\n",
    "    return new_login\n",
    "\n",
    "for line in data_lines:\n",
    "    try:\n",
    "        user_id = int(line[0])\n",
    "        ativo = line[1].lower() == 'true'\n",
    "        data_criacao = line[2].strip(\"'\")\n",
    "        email = line[5].strip(\"'\") if len(line) > 5 else f\"user{user_id}@example.com\"\n",
    "        matricula = line[6].strip(\"'\") if len(line) > 6 and line[6] != 'NULL' else None\n",
    "        nome = line[8].strip(\"'\") if len(line) > 8 else f\"User {user_id}\"\n",
    "        senha_original = line[9].strip(\"'\") if len(line) > 9 else \"default_hash\"\n",
    "        lotacao = line[20].strip(\"'\") if len(line) > 20 and line[20] != 'NULL' else None\n",
    "        \n",
    "        # Gerar login a partir do email (primeira parte antes do @)\n",
    "        base_login = email.split('@')[0] if email else f\"user_{user_id}\"\n",
    "        base_login = base_login.lower().replace(' ', '.').replace('_', '.')\n",
    "        \n",
    "        # Garantir unicidade do login\n",
    "        login = get_unique_login(base_login, user_id)\n",
    "        \n",
    "        # Usar a senha original como password_hash (jÃ¡ vem hasheada do banco antigo)\n",
    "        password_hash = senha_original\n",
    "        \n",
    "        # Adicionar Ã  tabela usuarios\n",
    "        usuarios_data.append({\n",
    "            'id': user_id,\n",
    "            'login': login,\n",
    "            'email': email,\n",
    "            'password_hash': password_hash,\n",
    "            'nome': nome,\n",
    "            'data_criacao': data_criacao,\n",
    "            'ativo': ativo,\n",
    "        })\n",
    "        usuarios_ids.add(user_id)\n",
    "        \n",
    "        # Adicionar Ã  tabela fiscais se matricula existir\n",
    "        if matricula and matricula != '0' and matricula != '':\n",
    "            fiscais_data.append({\n",
    "                'id': user_id,\n",
    "                'matricula': matricula,\n",
    "                'lotacao': lotacao,\n",
    "                'data_criacao': data_criacao,\n",
    "                'ativo': ativo,\n",
    "            })\n",
    "        \n",
    "    except (ValueError, IndexError) as e:\n",
    "        continue\n",
    "\n",
    "# Criar DataFrames com Polars\n",
    "df_usuarios = pl.DataFrame(usuarios_data)\n",
    "df_fiscais = pl.DataFrame(fiscais_data)\n",
    "\n",
    "# Converter datas para datetime\n",
    "def convert_dates(df, columns):\n",
    "    for col in columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).map_elements(parse_datetime_safe, return_dtype=pl.Datetime('us')).alias(col)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "df_usuarios = convert_dates(df_usuarios, ['data_criacao'])\n",
    "df_fiscais = convert_dates(df_fiscais, ['data_criacao'])\n",
    "\n",
    "# Remover duplicatas de login (manter primeiro)\n",
    "df_usuarios = df_usuarios.unique(subset=['login'], keep='first')\n",
    "\n",
    "# Manter apenas fiscais cujos IDs estÃ£o em usuarios\n",
    "valid_usuario_ids = set(df_usuarios['id'].to_list())\n",
    "df_fiscais = df_fiscais.filter(pl.col('id').is_in(valid_usuario_ids))\n",
    "\n",
    "print(f\"\\nğŸ“Š USUARIOS - Total de registros: {len(df_usuarios)}\")\n",
    "print(df_usuarios.head(3))\n",
    "\n",
    "print(f\"\\nğŸ” FISCAIS - Total de registros: {len(df_fiscais)}\")\n",
    "print(df_fiscais.head(3))\n",
    "\n",
    "# Conectar ao PostgreSQL\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='agefis',\n",
    "        user='postgres',\n",
    "        password='postgres',\n",
    "        port=5432\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Query para inserir em usuarios\n",
    "    insert_usuarios = \"\"\"\n",
    "        INSERT INTO \"seguranca\".\"usuarios\" \n",
    "        (id, login, email, password_hash, nome, data_criacao, ativo)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            login = EXCLUDED.login,\n",
    "            email = EXCLUDED.email,\n",
    "            password_hash = EXCLUDED.password_hash,\n",
    "            nome = EXCLUDED.nome,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query para inserir em fiscais\n",
    "    insert_fiscais = \"\"\"\n",
    "        INSERT INTO \"fiscalizacao\".\"fiscais\" \n",
    "        (id, matricula, lotacao, data_criacao, ativo)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            matricula = EXCLUDED.matricula,\n",
    "            lotacao = EXCLUDED.lotacao,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar dados para usuarios\n",
    "    usuarios_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['login'],\n",
    "            row['email'],\n",
    "            row['password_hash'],\n",
    "            row['nome'],\n",
    "            row['data_criacao'],\n",
    "            row['ativo'],\n",
    "        )\n",
    "        for row in df_usuarios.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    # Preparar dados para fiscais\n",
    "    fiscais_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['matricula'],\n",
    "            row['lotacao'],\n",
    "            row['data_criacao'],\n",
    "            row['ativo'],\n",
    "        )\n",
    "        for row in df_fiscais.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    # Executar inserts em batch\n",
    "    print(\"\\nâ³ Inserindo em 'seguranca.usuarios'...\")\n",
    "    execute_batch(cursor, insert_usuarios, usuarios_to_insert, page_size=100)\n",
    "    conn.commit()\n",
    "    print(f\"âœ… {len(usuarios_to_insert)} usuÃ¡rios inseridos!\")\n",
    "    \n",
    "    if fiscais_to_insert:\n",
    "        print(\"\\nâ³ Inserindo em 'fiscalizacao.fiscais'...\")\n",
    "        execute_batch(cursor, insert_fiscais, fiscais_to_insert, page_size=100)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… {len(fiscais_to_insert)} fiscais inseridos!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Nenhum fiscal para inserir\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao inserir dados: {e}\")\n",
    "    conn.rollback()\n",
    "    \n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bd9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total de linhas extraÃ­das: 1393\n",
      "ğŸ“‹ Logins existentes no banco: 885\n",
      "âœ… Todos os logins sÃ£o Ãºnicos no DataFrame\n",
      "\n",
      "ğŸ“Š USUARIOS - Total de registros: 1393\n",
      "shape: (3, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id      â”† login          â”† email         â”† password_hash â”† nome          â”† data_criacao  â”† ativo â”‚\n",
      "â”‚ ---     â”† ---            â”† ---           â”† ---           â”† ---           â”† ---           â”† ---   â”‚\n",
      "â”‚ i64     â”† str            â”† str           â”† str           â”† str           â”† datetime[Î¼s]  â”† bool  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 75494   â”† paula.carvalho â”† paula.carvalh â”† e352da19e4702 â”† PAULA NATASHA â”† 2019-01-07    â”† true  â”‚\n",
      "â”‚         â”† .75494         â”† o@agefis.fort â”† e15ad517c7189 â”† RODRIGUES     â”† 09:59:00      â”†       â”‚\n",
      "â”‚         â”†                â”† alezâ€¦         â”† c3d2â€¦         â”† VALENTâ€¦       â”†               â”†       â”‚\n",
      "â”‚ 4531376 â”† francisca.marq â”† francisca.mar â”† b06fcaa1e1d12 â”† FRANCISCA     â”† 2022-10-26    â”† true  â”‚\n",
      "â”‚         â”† ues.4531376    â”† ques@s10.fort â”† fe35424416031 â”† EVELMA VIEIRA â”† 10:22:22.156  â”†       â”‚\n",
      "â”‚         â”†                â”† alezâ€¦         â”† 254eâ€¦         â”† DE SOUâ€¦       â”†               â”†       â”‚\n",
      "â”‚ 48140   â”† monica.cordeir â”† monica.cordei â”† 711a290b39dee â”† MONICA        â”† 2021-06-18    â”† true  â”‚\n",
      "â”‚         â”† o.48140        â”† ro@agefis.for â”† 5d29f017b11ca â”† CORDEIRO      â”† 16:23:00      â”†       â”‚\n",
      "â”‚         â”†                â”† taleâ€¦         â”† 0419â€¦         â”† PIMENTEL      â”†               â”†       â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ğŸ” FISCAIS - Total de registros: 1393\n",
      "shape: (3, 5)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id      â”† matricula   â”† lotacao â”† data_criacao            â”† ativo â”‚\n",
      "â”‚ ---     â”† ---         â”† ---     â”† ---                     â”† ---   â”‚\n",
      "â”‚ i64     â”† str         â”† str     â”† datetime[Î¼s]            â”† bool  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 75494   â”† 8709301     â”† 37      â”† 2019-01-07 09:59:00     â”† true  â”‚\n",
      "â”‚ 4531376 â”† 45744319387 â”† 15      â”† 2022-10-26 10:22:22.156 â”† true  â”‚\n",
      "â”‚ 48140   â”† 8721401     â”† 37      â”† 2021-06-18 16:23:00     â”† true  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â³ Inserindo em 'seguranca.usuarios'...\n",
      "âœ… 1393 usuÃ¡rios inseridos!\n",
      "\n",
      "â³ Inserindo em 'fiscalizacao.fiscais'...\n",
      "âœ… 1393 usuÃ¡rios inseridos!\n",
      "\n",
      "â³ Inserindo em 'fiscalizacao.fiscais'...\n",
      "âœ… 1393 fiscais inseridos!\n",
      "âœ… 1393 fiscais inseridos!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# Leitura do arquivo SQL\n",
    "with open('usuario_202512021153.sql', 'r', encoding='utf-8') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "def parse_sql_values(sql_content):\n",
    "    \"\"\"Parser robusto que respeita strings com parÃªnteses e vÃ­rgulas\"\"\"\n",
    "    data_rows = []\n",
    "    sql_content = sql_content.replace('\\n', ' ').replace('\\r', '')\n",
    "    \n",
    "    i = 0\n",
    "    current_tuple = []\n",
    "    current_value = ''\n",
    "    in_string = False\n",
    "    paren_depth = 0\n",
    "    \n",
    "    while i < len(sql_content):\n",
    "        char = sql_content[i]\n",
    "        \n",
    "        if char == \"'\" and not in_string:\n",
    "            in_string = True\n",
    "            current_value += char\n",
    "        elif char == \"'\" and in_string:\n",
    "            if i + 1 < len(sql_content) and sql_content[i + 1] == \"'\":\n",
    "                current_value += \"''\"\n",
    "                i += 1\n",
    "            else:\n",
    "                in_string = False\n",
    "                current_value += char\n",
    "        elif in_string:\n",
    "            current_value += char\n",
    "        elif char == '(' and not in_string:\n",
    "            if paren_depth == 0:\n",
    "                current_tuple = []\n",
    "                current_value = ''\n",
    "            else:\n",
    "                current_value += char\n",
    "            paren_depth += 1\n",
    "        elif char == ')' and not in_string:\n",
    "            paren_depth -= 1\n",
    "            if paren_depth == 0:\n",
    "                if current_value.strip():\n",
    "                    current_tuple.append(current_value.strip())\n",
    "                if len(current_tuple) >= 21:\n",
    "                    first_val = current_tuple[0] if current_tuple else ''\n",
    "                    if first_val.isdigit():\n",
    "                        data_rows.append(current_tuple)\n",
    "                current_tuple = []\n",
    "                current_value = ''\n",
    "            else:\n",
    "                current_value += char\n",
    "        elif char == ',' and not in_string:\n",
    "            if paren_depth == 1:\n",
    "                current_tuple.append(current_value.strip())\n",
    "                current_value = ''\n",
    "            elif paren_depth == 0:\n",
    "                pass\n",
    "            else:\n",
    "                current_value += char\n",
    "        else:\n",
    "            if paren_depth > 0:\n",
    "                current_value += char\n",
    "        i += 1\n",
    "    \n",
    "    return data_rows\n",
    "\n",
    "data_lines = parse_sql_values(sql_content)\n",
    "\n",
    "print(f\"âœ… Total de linhas extraÃ­das: {len(data_lines)}\")\n",
    "\n",
    "# Primeiro, buscar logins jÃ¡ existentes no banco\n",
    "existing_logins = set()\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='agefis',\n",
    "        user='postgres',\n",
    "        password='postgres',\n",
    "        port=5432\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT login FROM \"seguranca\".\"usuarios\"')\n",
    "    existing_logins = set(row[0] for row in cursor.fetchall())\n",
    "    print(f\"ğŸ“‹ Logins existentes no banco: {len(existing_logins)}\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ NÃ£o foi possÃ­vel buscar logins existentes: {e}\")\n",
    "\n",
    "# Processar dados\n",
    "usuarios_data = []\n",
    "fiscais_data = []\n",
    "login_set = set(existing_logins)  # Iniciar com logins do banco\n",
    "usuarios_ids = set()\n",
    "\n",
    "def parse_datetime_safe(date_str):\n",
    "    if not date_str or date_str == 'NULL':\n",
    "        return None\n",
    "    date_str = date_str.strip(\"'\")\n",
    "    if 'BC' in date_str:\n",
    "        return None\n",
    "    for fmt in ['%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d']:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def get_unique_login(base_login, user_id, login_set):\n",
    "    \"\"\"Garante login Ãºnico considerando banco + sessÃ£o\"\"\"\n",
    "    if base_login not in login_set:\n",
    "        login_set.add(base_login)\n",
    "        return base_login\n",
    "    unique_login = f\"{base_login}.{user_id}\"\n",
    "    login_set.add(unique_login)\n",
    "    return unique_login\n",
    "\n",
    "for line in data_lines:\n",
    "    try:\n",
    "        user_id = int(line[0])\n",
    "        ativo = line[1].lower() == 'true'\n",
    "        data_criacao = line[2].strip(\"'\")\n",
    "        email = line[5].strip(\"'\") if len(line) > 5 else f\"user{user_id}@example.com\"\n",
    "        matricula = line[6].strip(\"'\") if len(line) > 6 and line[6] != 'NULL' else None\n",
    "        nome = line[8].strip(\"'\") if len(line) > 8 else f\"User {user_id}\"\n",
    "        senha_original = line[9].strip(\"'\") if len(line) > 9 else \"default_hash\"\n",
    "        lotacao = line[20].strip(\"'\") if len(line) > 20 and line[20] != 'NULL' else None\n",
    "        \n",
    "        base_login = email.split('@')[0] if email else f\"user_{user_id}\"\n",
    "        base_login = base_login.lower().replace(' ', '.').replace('_', '.')\n",
    "        \n",
    "        login = get_unique_login(base_login, user_id, login_set)\n",
    "        \n",
    "        usuarios_data.append({\n",
    "            'id': user_id,\n",
    "            'login': login,\n",
    "            'email': email,\n",
    "            'password_hash': senha_original,\n",
    "            'nome': nome,\n",
    "            'data_criacao': data_criacao,\n",
    "            'ativo': ativo,\n",
    "        })\n",
    "        usuarios_ids.add(user_id)\n",
    "        \n",
    "        if matricula and matricula != '0' and matricula != '':\n",
    "            fiscais_data.append({\n",
    "                'id': user_id,\n",
    "                'matricula': matricula,\n",
    "                'lotacao': lotacao,\n",
    "                'data_criacao': data_criacao,\n",
    "                'ativo': ativo,\n",
    "            })\n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"Erro ao processar linha ID {line[0] if line else 'N/A'}: {e}\")\n",
    "        continue\n",
    "\n",
    "df_usuarios = pl.DataFrame(usuarios_data)\n",
    "df_fiscais = pl.DataFrame(fiscais_data)\n",
    "\n",
    "def convert_dates(df, columns):\n",
    "    for col in columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).map_elements(parse_datetime_safe, return_dtype=pl.Datetime('us')).alias(col)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "df_usuarios = convert_dates(df_usuarios, ['data_criacao'])\n",
    "df_fiscais = convert_dates(df_fiscais, ['data_criacao'])\n",
    "\n",
    "# Verificar duplicatas no DataFrame\n",
    "duplicated = df_usuarios.group_by('login').len().filter(pl.col('len') > 1)\n",
    "if len(duplicated) > 0:\n",
    "    print(f\"âš ï¸ Logins duplicados no DataFrame: {len(duplicated)}\")\n",
    "else:\n",
    "    print(\"âœ… Todos os logins sÃ£o Ãºnicos no DataFrame\")\n",
    "\n",
    "valid_usuario_ids = set(df_usuarios['id'].to_list())\n",
    "df_fiscais = df_fiscais.filter(pl.col('id').is_in(valid_usuario_ids))\n",
    "\n",
    "print(f\"\\nğŸ“Š USUARIOS - Total de registros: {len(df_usuarios)}\")\n",
    "print(df_usuarios.head(3))\n",
    "print(f\"\\nğŸ” FISCAIS - Total de registros: {len(df_fiscais)}\")\n",
    "print(df_fiscais.head(3))\n",
    "\n",
    "# Inserir no PostgreSQL\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='agefis',\n",
    "        user='postgres',\n",
    "        password='postgres',\n",
    "        port=5432\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    insert_usuarios = \"\"\"\n",
    "        INSERT INTO \"seguranca\".\"usuarios\" \n",
    "        (id, login, email, password_hash, nome, data_criacao, ativo)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            login = EXCLUDED.login,\n",
    "            email = EXCLUDED.email,\n",
    "            password_hash = EXCLUDED.password_hash,\n",
    "            nome = EXCLUDED.nome,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    insert_fiscais = \"\"\"\n",
    "        INSERT INTO \"fiscalizacao\".\"fiscais\" \n",
    "        (id, matricula, lotacao, data_criacao, ativo)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            matricula = EXCLUDED.matricula,\n",
    "            lotacao = EXCLUDED.lotacao,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    usuarios_to_insert = [\n",
    "        (row['id'], row['login'], row['email'], row['password_hash'], \n",
    "         row['nome'], row['data_criacao'], row['ativo'])\n",
    "        for row in df_usuarios.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    fiscais_to_insert = [\n",
    "        (row['id'], row['matricula'], row['lotacao'], row['data_criacao'], row['ativo'])\n",
    "        for row in df_fiscais.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nâ³ Inserindo em 'seguranca.usuarios'...\")\n",
    "    execute_batch(cursor, insert_usuarios, usuarios_to_insert, page_size=100)\n",
    "    conn.commit()\n",
    "    print(f\"âœ… {len(usuarios_to_insert)} usuÃ¡rios inseridos!\")\n",
    "    \n",
    "    if fiscais_to_insert:\n",
    "        print(\"\\nâ³ Inserindo em 'fiscalizacao.fiscais'...\")\n",
    "        execute_batch(cursor, insert_fiscais, fiscais_to_insert, page_size=100)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… {len(fiscais_to_insert)} fiscais inseridos!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao inserir dados: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef9133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "  File \"/tmp/ipykernel_413901/4095079106.py\", line 2, in <module>\n",
      "    import polars as pl\n",
      "ModuleNotFoundError: No module named 'polars'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/home/joao/dev/mota/AGEFIS_FISCALIZE_COMSUME/.venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# ============================================================\n",
    "# PARSER E IMPORTAÃ‡ÃƒO DE CNAE\n",
    "# ============================================================\n",
    "\n",
    "# Leitura do arquivo SQL\n",
    "with open('cnae_202512040905.sql', 'r', encoding='utf-8') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "def parse_cnae_sql(sql_content):\n",
    "    \"\"\"Parser para extrair dados da tabela CNAE do SQL\"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    # Regex para capturar as tuplas de INSERT\n",
    "    # Formato: (id, ativo, 'data_criacao', 'codigo', 'descricao')\n",
    "    pattern = r\"\\((\\d+),(true|false),'([^']+)','([^']+)','([^']+)'\\)\"\n",
    "    \n",
    "    matches = re.findall(pattern, sql_content, re.IGNORECASE)\n",
    "    \n",
    "    for match in matches:\n",
    "        id_val, ativo, data_criacao, codigo, descricao = match\n",
    "        data_rows.append({\n",
    "            'id': int(id_val),\n",
    "            'ativo': ativo.lower() == 'true',\n",
    "            'data_criacao': data_criacao,\n",
    "            'codigo': codigo,\n",
    "            'descricao': descricao\n",
    "        })\n",
    "    \n",
    "    return data_rows\n",
    "\n",
    "def parse_datetime_safe(date_str):\n",
    "    \"\"\"Converte string de data para datetime de forma segura\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    for fmt in ['%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d']:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Extrair dados\n",
    "data_rows = parse_cnae_sql(sql_content)\n",
    "print(f\"âœ… Total de registros CNAE extraÃ­dos: {len(data_rows)}\")\n",
    "\n",
    "# Mostrar amostra\n",
    "print(f\"\\nğŸ“Š Amostra dos primeiros 5 registros:\")\n",
    "for row in data_rows[:5]:\n",
    "    print(f\"   ID: {row['id']} | CÃ³digo: {row['codigo']} | {row['descricao'][:50]}...\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ EstatÃ­sticas:\")\n",
    "print(f\"   - Total de registros: {len(data_rows)}\")\n",
    "if data_rows:\n",
    "    ids = [r['id'] for r in data_rows]\n",
    "    print(f\"   - ID mÃ­nimo: {min(ids)}\")\n",
    "    print(f\"   - ID mÃ¡ximo: {max(ids)}\")\n",
    "\n",
    "# ============================================================\n",
    "# INSERIR NO BANCO REMOTO\n",
    "# ============================================================\n",
    "\n",
    "# ConexÃ£o com o banco remoto\n",
    "DB_URL = \"postgres://postgres:S3nh4S3gur4@62.72.9.97:5432/agefis\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(DB_URL)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"\\nğŸ”Œ Conectado ao banco remoto!\")\n",
    "    \n",
    "    # Query de inserÃ§Ã£o com UPSERT\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO \"fiscalizacao\".\"cnaes\" \n",
    "        (id, codigo, descricao, ativo, data_criacao)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            codigo = EXCLUDED.codigo,\n",
    "            descricao = EXCLUDED.descricao,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar dados para inserÃ§Ã£o\n",
    "    data_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['codigo'],\n",
    "            row['descricao'],\n",
    "            row['ativo'],\n",
    "            parse_datetime_safe(row['data_criacao'])\n",
    "        )\n",
    "        for row in data_rows\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nâ³ Inserindo {len(data_to_insert)} registros em 'fiscalizacao.cnaes'...\")\n",
    "    \n",
    "    # Executar em batch\n",
    "    execute_batch(cursor, insert_query, data_to_insert, page_size=100)\n",
    "    conn.commit()\n",
    "    \n",
    "    print(f\"âœ… {len(data_to_insert)} registros de CNAE inseridos/atualizados com sucesso!\")\n",
    "    \n",
    "    # Verificar quantos registros existem agora\n",
    "    cursor.execute('SELECT COUNT(*) FROM \"fiscalizacao\".\"cnaes\"')\n",
    "    total = cursor.fetchone()[0]\n",
    "    print(f\"\\nğŸ“Š Total de registros na tabela cnaes: {total}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro: {e}\")\n",
    "    if 'conn' in dir():\n",
    "        conn.rollback()\n",
    "\n",
    "finally:\n",
    "    if 'cursor' in dir():\n",
    "        cursor.close()\n",
    "    if 'conn' in dir():\n",
    "        conn.close()\n",
    "        print(\"\\nğŸ”Œ ConexÃ£o fechada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0a7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
