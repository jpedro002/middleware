{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828393cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas extra√≠das: 172\n",
      "IDs encontrados: 172\n",
      "IDs antes faltantes agora encontrados: [103171, 107729, 256460, 107761, 102749, 107545, 107611, 104241, 96208, 434600, 107728, 95463, 107738, 96209, 256427, 107734, 107779]\n",
      "IDs ainda faltando: []\n",
      "\n",
      "Total de registros a importar: 172\n",
      "\n",
      "Primeiros 5 registros:\n",
      "shape: (5, 6)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ id     ‚îÜ nome             ‚îÜ descricao                ‚îÜ fundo_municipal_id ‚îÜ ativo ‚îÜ data_criacao ‚îÇ\n",
      "‚îÇ ---    ‚îÜ ---              ‚îÜ ---                      ‚îÜ ---                ‚îÜ ---   ‚îÜ ---          ‚îÇ\n",
      "‚îÇ i64    ‚îÜ str              ‚îÜ str                      ‚îÜ i64                ‚îÜ bool  ‚îÜ datetime[Œºs] ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 103187 ‚îÜ 3.10 Posturas e  ‚îÜ Na zona de orla          ‚îÜ 3                  ‚îÜ true  ‚îÜ 2017-10-20   ‚îÇ\n",
      "‚îÇ        ‚îÜ pr√°ticas inade‚Ä¶  ‚îÜ                          ‚îÜ                    ‚îÜ       ‚îÜ 12:12:36.504 ‚îÇ\n",
      "‚îÇ 103171 ‚îÜ 3.2 Posturas e   ‚îÜ Exemplos: passeio        ‚îÜ 3                  ‚îÜ true  ‚îÜ 2017-11-13   ‚îÇ\n",
      "‚îÇ        ‚îÜ pr√°ticas inadeq‚Ä¶ ‚îÜ (cal√ßada) ir‚Ä¶            ‚îÜ                    ‚îÜ       ‚îÜ 14:18:28.037 ‚îÇ\n",
      "‚îÇ 103169 ‚îÜ 3.1 Posturas e   ‚îÜ Falta de licen√ßa vigente ‚îÜ 3                  ‚îÜ true  ‚îÜ 2017-11-14   ‚îÇ\n",
      "‚îÇ        ‚îÜ pr√°ticas inadeq‚Ä¶ ‚îÜ                          ‚îÜ                    ‚îÜ       ‚îÜ 12:07:16.409 ‚îÇ\n",
      "‚îÇ 141504 ‚îÜ 18.13 Produtos e ‚îÜ Produtos e servi√ßos n√£o  ‚îÜ 0                  ‚îÜ true  ‚îÜ 2018-01-31   ‚îÇ\n",
      "‚îÇ        ‚îÜ servi√ßos n√£o ‚Ä¶   ‚îÜ relaci‚Ä¶                  ‚îÜ                    ‚îÜ       ‚îÜ 11:57:25.444 ‚îÇ\n",
      "‚îÇ 152692 ‚îÜ 6.4 Im√≥vel n√£o   ‚îÜ Im√≥vel n√£o interligado √† ‚îÜ 0                  ‚îÜ true  ‚îÜ 2017-11-14   ‚îÇ\n",
      "‚îÇ        ‚îÜ interligado √† r‚Ä¶ ‚îÜ rede ‚Ä¶                   ‚îÜ                    ‚îÜ       ‚îÜ 15:08:37.808 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "‚úÖ 172 registros inseridos/atualizados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Leitura do arquivo SQL\n",
    "with open('grupodemanda_202512021151.sql', 'r', encoding='utf-8') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "# Parser linha por linha com tratamento especial para strings\n",
    "def parse_line_by_line(sql_content):\n",
    "    \"\"\"Parse linha por linha com tratamento especial para strings\"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    lines = sql_content.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line.startswith('(') and '\\t (' not in line and '\t (' not in line:\n",
    "            if '(' not in line or not any(c.isdigit() for c in line[:20]):\n",
    "                continue\n",
    "        \n",
    "        # Extrair tupla da linha\n",
    "        if '(' in line and ')' in line:\n",
    "            start = line.find('(')\n",
    "            end = line.rfind(')')\n",
    "            \n",
    "            if start >= 0 and end > start:\n",
    "                tuple_content = line[start+1:end]\n",
    "                \n",
    "                # Parse manual respeitando strings\n",
    "                values = []\n",
    "                current = ''\n",
    "                in_string = False\n",
    "                \n",
    "                for char in tuple_content:\n",
    "                    if char == \"'\" and not in_string:\n",
    "                        in_string = True\n",
    "                        current += char\n",
    "                    elif char == \"'\" and in_string:\n",
    "                        in_string = False\n",
    "                        current += char\n",
    "                    elif char == ',' and not in_string:\n",
    "                        values.append(current.strip())\n",
    "                        current = ''\n",
    "                    else:\n",
    "                        current += char\n",
    "                \n",
    "                if current:\n",
    "                    values.append(current.strip())\n",
    "                \n",
    "                if len(values) >= 9 and values[0].isdigit():\n",
    "                    data_rows.append(values)\n",
    "    \n",
    "    return data_rows\n",
    "\n",
    "# Usar o parser linha por linha\n",
    "data_lines = parse_line_by_line(sql_content)\n",
    "\n",
    "print(f\"Total de linhas extra√≠das: {len(data_lines)}\")\n",
    "\n",
    "# IDs que estavam faltando para verificar\n",
    "missing_ids = [103171, 107729, 256460, 107761, 102749, 107545, 107611, 104241, \n",
    "               96208, 434600, 107728, 95463, 107738, 96209, 256427, 107734, 107779]\n",
    "\n",
    "found_ids = [int(line[0]) for line in data_lines if line[0].isdigit()]\n",
    "print(f\"IDs encontrados: {len(found_ids)}\")\n",
    "\n",
    "missing_found = [id for id in missing_ids if id in found_ids]\n",
    "still_missing = [id for id in missing_ids if id not in found_ids]\n",
    "print(f\"IDs antes faltantes agora encontrados: {missing_found}\")\n",
    "print(f\"IDs ainda faltando: {still_missing}\")\n",
    "\n",
    "# Processar cada linha de dados\n",
    "processed_data = []\n",
    "for line in data_lines:\n",
    "    try:\n",
    "        id_val = int(line[0])\n",
    "        ativo = line[1].lower() == 'true'\n",
    "        data_criacao = line[2].strip(\"'\")\n",
    "        descricao = line[3].strip(\"'\")\n",
    "        nome = line[4].strip(\"'\")\n",
    "        # Usar 0 quando fundo_municipal_id for NULL (n√£o permite null na tabela)\n",
    "        fundo_municipal_id = 0 if line[7] == 'NULL' or line[7] is None or line[7] == '' else int(line[7])\n",
    "        \n",
    "        processed_data.append({\n",
    "            'id': id_val,\n",
    "            'nome': nome,\n",
    "            'descricao': descricao,\n",
    "            'fundo_municipal_id': fundo_municipal_id,\n",
    "            'ativo': ativo,\n",
    "            'data_criacao': data_criacao,\n",
    "        })\n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"Erro ao processar linha: {line[:3]}... - {e}\")\n",
    "        continue\n",
    "\n",
    "# Criar DataFrame com Polars\n",
    "df = pl.DataFrame(processed_data)\n",
    "\n",
    "# Converter data_criacao para datetime\n",
    "def parse_datetime(date_str):\n",
    "    \"\"\"Converte string de data para datetime, suportando com e sem milissegundos\"\"\"\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    except ValueError:\n",
    "        return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col('data_criacao').map_elements(parse_datetime, return_dtype=pl.Datetime('us')).alias('data_criacao')\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal de registros a importar: {len(df)}\")\n",
    "print(\"\\nPrimeiros 5 registros:\")\n",
    "print(df.head(5))\n",
    "\n",
    "# Conectar ao PostgreSQL e fazer o insert\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='agefis',\n",
    "        user='postgres',\n",
    "        password='postgres',\n",
    "        port=5432\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Query sem a coluna afinidades\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO \"fiscalizacao\".\"grupos_ocorrencia\" \n",
    "        (id, nome, descricao, fundo_municipal_id, ativo, data_criacao)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            nome = EXCLUDED.nome,\n",
    "            descricao = EXCLUDED.descricao,\n",
    "            fundo_municipal_id = EXCLUDED.fundo_municipal_id,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Converter DataFrame para lista de tuplas\n",
    "    data_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['nome'],\n",
    "            row['descricao'],\n",
    "            row['fundo_municipal_id'],\n",
    "            row['ativo'],\n",
    "            row['data_criacao']\n",
    "        )\n",
    "        for row in df.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    # Executar insert em batch\n",
    "    execute_batch(cursor, insert_query, data_to_insert, page_size=100)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"\\n‚úÖ {len(data_to_insert)} registros inseridos/atualizados com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao inserir dados: {e}\")\n",
    "    if 'conn' in dir():\n",
    "        conn.rollback()\n",
    "    \n",
    "finally:\n",
    "    if 'cursor' in dir():\n",
    "        cursor.close()\n",
    "    if 'conn' in dir():\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a03cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas extra√≠das: 885\n",
      "Colunas por linha (primeiro): 33\n",
      "Colunas por linha (min/max): 33/34\n",
      "\n",
      "üìä USUARIOS - Total de registros: 885\n",
      "shape: (3, 7)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ id      ‚îÜ login          ‚îÜ email         ‚îÜ password_hash ‚îÜ nome          ‚îÜ data_criacao  ‚îÜ ativo ‚îÇ\n",
      "‚îÇ ---     ‚îÜ ---            ‚îÜ ---           ‚îÜ ---           ‚îÜ ---           ‚îÜ ---           ‚îÜ ---   ‚îÇ\n",
      "‚îÇ i64     ‚îÜ str            ‚îÜ str           ‚îÜ str           ‚îÜ str           ‚îÜ datetime[Œºs]  ‚îÜ bool  ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 54123   ‚îÜ silvia.maciel  ‚îÜ silvia.maciel ‚îÜ b06fcaa1e1d12 ‚îÜ Silvia        ‚îÜ 2019-01-03    ‚îÜ true  ‚îÇ\n",
      "‚îÇ         ‚îÜ                ‚îÜ @agefis.forta ‚îÜ fe35424416031 ‚îÜ Germana Luz   ‚îÜ 10:36:23.438  ‚îÜ       ‚îÇ\n",
      "‚îÇ         ‚îÜ                ‚îÜ leza‚Ä¶         ‚îÜ 254e‚Ä¶         ‚îÜ Maciel        ‚îÜ               ‚îÜ       ‚îÇ\n",
      "‚îÇ 2165934 ‚îÜ andre.arrais   ‚îÜ andre.arrais@ ‚îÜ 46135bceb5ebc ‚îÜ Marcos Andr√©  ‚îÜ 2020-02-18    ‚îÜ true  ‚îÇ\n",
      "‚îÇ         ‚îÜ                ‚îÜ seuma.fortale ‚îÜ 5b7dff279caa7 ‚îÜ Arrais de     ‚îÜ 16:09:00      ‚îÜ       ‚îÇ\n",
      "‚îÇ         ‚îÜ                ‚îÜ za.c‚Ä¶         ‚îÜ c9a4‚Ä¶         ‚îÜ Almeida       ‚îÜ               ‚îÜ       ‚îÇ\n",
      "‚îÇ 56643   ‚îÜ fernando.sarai ‚îÜ fernando.sara ‚îÜ b06fcaa1e1d12 ‚îÜ FERNANDO JOSE ‚îÜ 2017-07-20    ‚îÜ true  ‚îÇ\n",
      "‚îÇ         ‚îÜ va             ‚îÜ iva@agefis.fo ‚îÜ fe35424416031 ‚îÜ LIMA SARAIVA  ‚îÜ 16:10:00      ‚îÜ       ‚îÇ\n",
      "‚îÇ         ‚îÜ                ‚îÜ rtal‚Ä¶         ‚îÜ 254e‚Ä¶         ‚îÜ               ‚îÜ               ‚îÜ       ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "üîê FISCAIS - Total de registros: 885\n",
      "shape: (3, 5)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ id      ‚îÜ matricula   ‚îÜ lotacao ‚îÜ data_criacao            ‚îÜ ativo ‚îÇ\n",
      "‚îÇ ---     ‚îÜ ---         ‚îÜ ---     ‚îÜ ---                     ‚îÜ ---   ‚îÇ\n",
      "‚îÇ i64     ‚îÜ str         ‚îÜ str     ‚îÜ datetime[Œºs]            ‚îÜ bool  ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 75494   ‚îÜ 8709301     ‚îÜ 37      ‚îÜ 2019-01-07 09:59:00     ‚îÜ true  ‚îÇ\n",
      "‚îÇ 4531376 ‚îÜ 45744319387 ‚îÜ 15      ‚îÜ 2022-10-26 10:22:22.156 ‚îÜ true  ‚îÇ\n",
      "‚îÇ 48140   ‚îÜ 8721401     ‚îÜ 37      ‚îÜ 2021-06-18 16:23:00     ‚îÜ true  ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "‚è≥ Inserindo em 'seguranca.usuarios'...\n",
      "\n",
      "‚è≥ Inserindo em 'seguranca.usuarios'...\n",
      "‚úÖ 885 usu√°rios inseridos!\n",
      "\n",
      "‚è≥ Inserindo em 'fiscalizacao.fiscais'...\n",
      "‚úÖ 885 usu√°rios inseridos!\n",
      "\n",
      "‚è≥ Inserindo em 'fiscalizacao.fiscais'...\n",
      "‚úÖ 885 fiscais inseridos!\n",
      "‚úÖ 885 fiscais inseridos!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import hashlib\n",
    "\n",
    "# Leitura do arquivo SQL\n",
    "with open('usuario_202512021153.sql', 'r', encoding='utf-8') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "# Extrair blocos de INSERT\n",
    "insert_blocks = re.findall(r'INSERT INTO usuario \\([^)]+\\) VALUES\\s+(.*?)(?=INSERT INTO|$)', sql_content, re.DOTALL)\n",
    "\n",
    "data_lines = []\n",
    "\n",
    "for block in insert_blocks:\n",
    "    # Encontrar todas as tuplas com par√™nteses\n",
    "    pattern = r'\\(([^)]+)\\)'\n",
    "    matches = re.findall(pattern, block)\n",
    "    \n",
    "    for match in matches:\n",
    "        parts = [p.strip() for p in match.split(',')]\n",
    "        # Verificar se √© um dado v√°lido (primeiro valor √© n√∫mero) e tem pelo menos as colunas esperadas\n",
    "        if len(parts) >= 21 and parts[0].isdigit():  # Precisa de pelo menos at√© setor_id (√≠ndice 20)\n",
    "            data_lines.append(parts)\n",
    "\n",
    "print(f\"Total de linhas extra√≠das: {len(data_lines)}\")\n",
    "if data_lines:\n",
    "    print(f\"Colunas por linha (primeiro): {len(data_lines[0])}\")\n",
    "    print(f\"Colunas por linha (min/max): {min(len(line) for line in data_lines)}/{max(len(line) for line in data_lines)}\")\n",
    "\n",
    "# Processar dados para a tabela usuarios\n",
    "usuarios_data = []\n",
    "fiscais_data = []\n",
    "login_counter = {}  # Para evitar logins duplicados\n",
    "usuarios_ids = set()  # Rastrear IDs de usu√°rios que ser√£o inseridos\n",
    "\n",
    "def parse_datetime_safe(date_str):\n",
    "    \"\"\"Converte string de data para datetime, suportando v√°rios formatos\"\"\"\n",
    "    if not date_str or date_str == 'NULL':\n",
    "        return None\n",
    "    \n",
    "    date_str = date_str.strip(\"'\")\n",
    "    \n",
    "    # Lista de formatos para tentar\n",
    "    formats = [\n",
    "        '%Y-%m-%d %H:%M:%S.%f',  # Com milissegundos\n",
    "        '%Y-%m-%d %H:%M:%S',      # Sem milissegundos\n",
    "        '%Y-%m-%d',                # Apenas data\n",
    "    ]\n",
    "    \n",
    "    # Trata caso especial de data inv√°lida com \"BC\"\n",
    "    if 'BC' in date_str:\n",
    "        return None\n",
    "    \n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_unique_login(base_login, user_id):\n",
    "    \"\"\"Garante que o login seja √∫nico adicionando um sufixo se necess√°rio\"\"\"\n",
    "    if base_login not in login_counter:\n",
    "        login_counter[base_login] = 0\n",
    "        return base_login\n",
    "    \n",
    "    login_counter[base_login] += 1\n",
    "    # Gera um login √∫nico com sufixo\n",
    "    new_login = f\"{base_login}{login_counter[base_login]}\"\n",
    "    return new_login\n",
    "\n",
    "for line in data_lines:\n",
    "    try:\n",
    "        user_id = int(line[0])\n",
    "        ativo = line[1].lower() == 'true'\n",
    "        data_criacao = line[2].strip(\"'\")\n",
    "        email = line[5].strip(\"'\") if len(line) > 5 else f\"user{user_id}@example.com\"\n",
    "        matricula = line[6].strip(\"'\") if len(line) > 6 and line[6] != 'NULL' else None\n",
    "        nome = line[8].strip(\"'\") if len(line) > 8 else f\"User {user_id}\"\n",
    "        senha_original = line[9].strip(\"'\") if len(line) > 9 else \"default_hash\"\n",
    "        lotacao = line[20].strip(\"'\") if len(line) > 20 and line[20] != 'NULL' else None\n",
    "        \n",
    "        # Gerar login a partir do email (primeira parte antes do @)\n",
    "        base_login = email.split('@')[0] if email else f\"user_{user_id}\"\n",
    "        base_login = base_login.lower().replace(' ', '.').replace('_', '.')\n",
    "        \n",
    "        # Garantir unicidade do login\n",
    "        login = get_unique_login(base_login, user_id)\n",
    "        \n",
    "        # Usar a senha original como password_hash (j√° vem hasheada do banco antigo)\n",
    "        password_hash = senha_original\n",
    "        \n",
    "        # Adicionar √† tabela usuarios\n",
    "        usuarios_data.append({\n",
    "            'id': user_id,\n",
    "            'login': login,\n",
    "            'email': email,\n",
    "            'password_hash': password_hash,\n",
    "            'nome': nome,\n",
    "            'data_criacao': data_criacao,\n",
    "            'ativo': ativo,\n",
    "        })\n",
    "        usuarios_ids.add(user_id)\n",
    "        \n",
    "        # Adicionar √† tabela fiscais se matricula existir\n",
    "        if matricula and matricula != '0' and matricula != '':\n",
    "            fiscais_data.append({\n",
    "                'id': user_id,\n",
    "                'matricula': matricula,\n",
    "                'lotacao': lotacao,\n",
    "                'data_criacao': data_criacao,\n",
    "                'ativo': ativo,\n",
    "            })\n",
    "        \n",
    "    except (ValueError, IndexError) as e:\n",
    "        continue\n",
    "\n",
    "# Criar DataFrames com Polars\n",
    "df_usuarios = pl.DataFrame(usuarios_data)\n",
    "df_fiscais = pl.DataFrame(fiscais_data)\n",
    "\n",
    "# Converter datas para datetime\n",
    "def convert_dates(df, columns):\n",
    "    for col in columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).map_elements(parse_datetime_safe, return_dtype=pl.Datetime('us')).alias(col)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "df_usuarios = convert_dates(df_usuarios, ['data_criacao'])\n",
    "df_fiscais = convert_dates(df_fiscais, ['data_criacao'])\n",
    "\n",
    "# Remover duplicatas de login (manter primeiro)\n",
    "df_usuarios = df_usuarios.unique(subset=['login'], keep='first')\n",
    "\n",
    "# Manter apenas fiscais cujos IDs est√£o em usuarios\n",
    "valid_usuario_ids = set(df_usuarios['id'].to_list())\n",
    "df_fiscais = df_fiscais.filter(pl.col('id').is_in(valid_usuario_ids))\n",
    "\n",
    "print(f\"\\nüìä USUARIOS - Total de registros: {len(df_usuarios)}\")\n",
    "print(df_usuarios.head(3))\n",
    "\n",
    "print(f\"\\nüîê FISCAIS - Total de registros: {len(df_fiscais)}\")\n",
    "print(df_fiscais.head(3))\n",
    "\n",
    "# Conectar ao PostgreSQL\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='agefis',\n",
    "        user='postgres',\n",
    "        password='postgres',\n",
    "        port=5432\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Query para inserir em usuarios\n",
    "    insert_usuarios = \"\"\"\n",
    "        INSERT INTO \"seguranca\".\"usuarios\" \n",
    "        (id, login, email, password_hash, nome, data_criacao, ativo)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            login = EXCLUDED.login,\n",
    "            email = EXCLUDED.email,\n",
    "            password_hash = EXCLUDED.password_hash,\n",
    "            nome = EXCLUDED.nome,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query para inserir em fiscais\n",
    "    insert_fiscais = \"\"\"\n",
    "        INSERT INTO \"fiscalizacao\".\"fiscais\" \n",
    "        (id, matricula, lotacao, data_criacao, ativo)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            matricula = EXCLUDED.matricula,\n",
    "            lotacao = EXCLUDED.lotacao,\n",
    "            ativo = EXCLUDED.ativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar dados para usuarios\n",
    "    usuarios_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['login'],\n",
    "            row['email'],\n",
    "            row['password_hash'],\n",
    "            row['nome'],\n",
    "            row['data_criacao'],\n",
    "            row['ativo'],\n",
    "        )\n",
    "        for row in df_usuarios.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    # Preparar dados para fiscais\n",
    "    fiscais_to_insert = [\n",
    "        (\n",
    "            row['id'],\n",
    "            row['matricula'],\n",
    "            row['lotacao'],\n",
    "            row['data_criacao'],\n",
    "            row['ativo'],\n",
    "        )\n",
    "        for row in df_fiscais.to_dicts()\n",
    "    ]\n",
    "    \n",
    "    # Executar inserts em batch\n",
    "    print(\"\\n‚è≥ Inserindo em 'seguranca.usuarios'...\")\n",
    "    execute_batch(cursor, insert_usuarios, usuarios_to_insert, page_size=100)\n",
    "    conn.commit()\n",
    "    print(f\"‚úÖ {len(usuarios_to_insert)} usu√°rios inseridos!\")\n",
    "    \n",
    "    if fiscais_to_insert:\n",
    "        print(\"\\n‚è≥ Inserindo em 'fiscalizacao.fiscais'...\")\n",
    "        execute_batch(cursor, insert_fiscais, fiscais_to_insert, page_size=100)\n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ {len(fiscais_to_insert)} fiscais inseridos!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Nenhum fiscal para inserir\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao inserir dados: {e}\")\n",
    "    conn.rollback()\n",
    "    \n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
